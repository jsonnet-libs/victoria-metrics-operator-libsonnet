{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='vmSingle', url='', help='"VMSingle  is fast, cost-effective and scalable time-series database."'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of VMSingle', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'operator.victoriametrics.com/v1beta1',
    kind: 'VMSingle',
  } + self.metadata.withName(name=name),
  '#spec':: d.obj(help='"VMSingleSpec defines the desired state of VMSingle"'),
  spec: {
    '#dnsConfig':: d.obj(help='"Specifies the DNS parameters of a pod.\\nParameters specified here will be merged to the generated DNS\\nconfiguration based on DNSPolicy."'),
    dnsConfig: {
      '#options':: d.obj(help='"A list of DNS resolver options.\\nThis will be merged with the base options generated from DNSPolicy.\\nDuplicated entries will be removed. Resolution options given in Options\\nwill override those that appear in the base DNSPolicy."'),
      options: {
        '#withName':: d.fn(help='"Required."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withValue':: d.fn(help='', args=[d.arg(name='value', type=d.T.string)]),
        withValue(value): { value: value },
      },
      '#withNameservers':: d.fn(help='"A list of DNS name server IP addresses.\\nThis will be appended to the base nameservers generated from DNSPolicy.\\nDuplicated nameservers will be removed."', args=[d.arg(name='nameservers', type=d.T.array)]),
      withNameservers(nameservers): { spec+: { dnsConfig+: { nameservers: if std.isArray(v=nameservers) then nameservers else [nameservers] } } },
      '#withNameserversMixin':: d.fn(help='"A list of DNS name server IP addresses.\\nThis will be appended to the base nameservers generated from DNSPolicy.\\nDuplicated nameservers will be removed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nameservers', type=d.T.array)]),
      withNameserversMixin(nameservers): { spec+: { dnsConfig+: { nameservers+: if std.isArray(v=nameservers) then nameservers else [nameservers] } } },
      '#withOptions':: d.fn(help='"A list of DNS resolver options.\\nThis will be merged with the base options generated from DNSPolicy.\\nDuplicated entries will be removed. Resolution options given in Options\\nwill override those that appear in the base DNSPolicy."', args=[d.arg(name='options', type=d.T.array)]),
      withOptions(options): { spec+: { dnsConfig+: { options: if std.isArray(v=options) then options else [options] } } },
      '#withOptionsMixin':: d.fn(help='"A list of DNS resolver options.\\nThis will be merged with the base options generated from DNSPolicy.\\nDuplicated entries will be removed. Resolution options given in Options\\nwill override those that appear in the base DNSPolicy."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='options', type=d.T.array)]),
      withOptionsMixin(options): { spec+: { dnsConfig+: { options+: if std.isArray(v=options) then options else [options] } } },
      '#withSearches':: d.fn(help='"A list of DNS search domains for host-name lookup.\\nThis will be appended to the base search paths generated from DNSPolicy.\\nDuplicated search paths will be removed."', args=[d.arg(name='searches', type=d.T.array)]),
      withSearches(searches): { spec+: { dnsConfig+: { searches: if std.isArray(v=searches) then searches else [searches] } } },
      '#withSearchesMixin':: d.fn(help='"A list of DNS search domains for host-name lookup.\\nThis will be appended to the base search paths generated from DNSPolicy.\\nDuplicated search paths will be removed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='searches', type=d.T.array)]),
      withSearchesMixin(searches): { spec+: { dnsConfig+: { searches+: if std.isArray(v=searches) then searches else [searches] } } },
    },
    '#extraEnvs':: d.obj(help='"ExtraEnvs that will be passed to the application container"'),
    extraEnvs: {
      '#withName':: d.fn(help='"Name of the environment variable. Must be a C_IDENTIFIER."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { name: name },
      '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
      withValue(value): { value: value },
    },
    '#hostAliases':: d.obj(help='"HostAliases provides mapping for ip and hostname,\\nthat would be propagated to pod,\\ncannot be used with HostNetwork."'),
    hostAliases: {
      '#withHostnames':: d.fn(help='"Hostnames for the above IP address."', args=[d.arg(name='hostnames', type=d.T.array)]),
      withHostnames(hostnames): { hostnames: if std.isArray(v=hostnames) then hostnames else [hostnames] },
      '#withHostnamesMixin':: d.fn(help='"Hostnames for the above IP address."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='hostnames', type=d.T.array)]),
      withHostnamesMixin(hostnames): { hostnames+: if std.isArray(v=hostnames) then hostnames else [hostnames] },
      '#withIp':: d.fn(help='"IP address of the host file entry."', args=[d.arg(name='ip', type=d.T.string)]),
      withIp(ip): { ip: ip },
    },
    '#host_aliases':: d.obj(help='"HostAliasesUnderScore provides mapping for ip and hostname,\\nthat would be propagated to pod,\\ncannot be used with HostNetwork.\\nHas Priority over hostAliases field"'),
    host_aliases: {
      '#withHostnames':: d.fn(help='"Hostnames for the above IP address."', args=[d.arg(name='hostnames', type=d.T.array)]),
      withHostnames(hostnames): { hostnames: if std.isArray(v=hostnames) then hostnames else [hostnames] },
      '#withHostnamesMixin':: d.fn(help='"Hostnames for the above IP address."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='hostnames', type=d.T.array)]),
      withHostnamesMixin(hostnames): { hostnames+: if std.isArray(v=hostnames) then hostnames else [hostnames] },
      '#withIp':: d.fn(help='"IP address of the host file entry."', args=[d.arg(name='ip', type=d.T.string)]),
      withIp(ip): { ip: ip },
    },
    '#image':: d.obj(help='"Image - docker image settings\\nif no specified operator uses default version from operator config"'),
    image: {
      '#withPullPolicy':: d.fn(help='"PullPolicy describes how to pull docker image"', args=[d.arg(name='pullPolicy', type=d.T.string)]),
      withPullPolicy(pullPolicy): { spec+: { image+: { pullPolicy: pullPolicy } } },
      '#withRepository':: d.fn(help="\"Repository contains name of docker image + it's repository if needed\"", args=[d.arg(name='repository', type=d.T.string)]),
      withRepository(repository): { spec+: { image+: { repository: repository } } },
      '#withTag':: d.fn(help='"Tag contains desired docker image version"', args=[d.arg(name='tag', type=d.T.string)]),
      withTag(tag): { spec+: { image+: { tag: tag } } },
    },
    '#imagePullSecrets':: d.obj(help='"ImagePullSecrets An optional list of references to secrets in the same namespace\\nto use for pulling images from registries\\nsee https://kubernetes.io/docs/concepts/containers/images/#referring-to-an-imagepullsecrets-on-a-pod"'),
    imagePullSecrets: {
      '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { name: name },
    },
    '#insertPorts':: d.obj(help='"InsertPorts - additional listen ports for data ingestion."'),
    insertPorts: {
      '#withGraphitePort':: d.fn(help='"GraphitePort listen port"', args=[d.arg(name='graphitePort', type=d.T.string)]),
      withGraphitePort(graphitePort): { spec+: { insertPorts+: { graphitePort: graphitePort } } },
      '#withInfluxPort':: d.fn(help='"InfluxPort listen port"', args=[d.arg(name='influxPort', type=d.T.string)]),
      withInfluxPort(influxPort): { spec+: { insertPorts+: { influxPort: influxPort } } },
      '#withOpenTSDBHTTPPort':: d.fn(help='"OpenTSDBHTTPPort for http connections."', args=[d.arg(name='openTSDBHTTPPort', type=d.T.string)]),
      withOpenTSDBHTTPPort(openTSDBHTTPPort): { spec+: { insertPorts+: { openTSDBHTTPPort: openTSDBHTTPPort } } },
      '#withOpenTSDBPort':: d.fn(help='"OpenTSDBPort for tcp and udp listen"', args=[d.arg(name='openTSDBPort', type=d.T.string)]),
      withOpenTSDBPort(openTSDBPort): { spec+: { insertPorts+: { openTSDBPort: openTSDBPort } } },
    },
    '#license':: d.obj(help='"License allows to configure license key to be used for enterprise features.\\nUsing license key is supported starting from VictoriaMetrics v1.94.0.\\nSee [here](https://docs.victoriametrics.com/enterprise)"'),
    license: {
      '#keyRef':: d.obj(help='"KeyRef is reference to secret with license key for enterprise features."'),
      keyRef: {
        '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
        withKey(key): { spec+: { license+: { keyRef+: { key: key } } } },
        '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { license+: { keyRef+: { name: name } } } },
        '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
        withOptional(optional): { spec+: { license+: { keyRef+: { optional: optional } } } },
      },
      '#withKey':: d.fn(help='"Enterprise license key. This flag is available only in [VictoriaMetrics enterprise](https://docs.victoriametrics.com/enterprise).\\nTo request a trial license, [go to](https://victoriametrics.com/products/enterprise/trial)"', args=[d.arg(name='key', type=d.T.string)]),
      withKey(key): { spec+: { license+: { key: key } } },
    },
    '#podMetadata':: d.obj(help='"PodMetadata configures Labels and Annotations which are propagated to the VMSingle pods."'),
    podMetadata: {
      '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be\\nset by external tools to store and retrieve arbitrary metadata. They are not\\nqueryable and should be preserved when modifying objects.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
      withAnnotations(annotations): { spec+: { podMetadata+: { annotations: annotations } } },
      '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be\\nset by external tools to store and retrieve arbitrary metadata. They are not\\nqueryable and should be preserved when modifying objects.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
      withAnnotationsMixin(annotations): { spec+: { podMetadata+: { annotations+: annotations } } },
      '#withLabels':: d.fn(help='"Labels Map of string keys and values that can be used to organize and categorize\\n(scope and select) objects. May match selectors of replication controllers\\nand services.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels"', args=[d.arg(name='labels', type=d.T.object)]),
      withLabels(labels): { spec+: { podMetadata+: { labels: labels } } },
      '#withLabelsMixin':: d.fn(help='"Labels Map of string keys and values that can be used to organize and categorize\\n(scope and select) objects. May match selectors of replication controllers\\nand services.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
      withLabelsMixin(labels): { spec+: { podMetadata+: { labels+: labels } } },
      '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although\\nsome resources may allow a client to request the generation of an appropriate name\\nautomatically. Name is primarily intended for creation idempotence and configuration\\ndefinition.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names"', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { podMetadata+: { name: name } } },
    },
    '#readinessGates':: d.obj(help='"ReadinessGates defines pod readiness gates"'),
    readinessGates: {
      '#withConditionType':: d.fn(help="\"ConditionType refers to a condition in the pod's condition list with matching type.\"", args=[d.arg(name='conditionType', type=d.T.string)]),
      withConditionType(conditionType): { conditionType: conditionType },
    },
    '#resources':: d.obj(help='"Resources container resource request and limits, https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\\nif not defined default resources from operator config will be used"'),
    resources: {
      '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
      claims: {
        '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
      },
      '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
      withClaims(claims): { spec+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } },
      '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
      withClaimsMixin(claims): { spec+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } },
      '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
      withLimits(limits): { spec+: { resources+: { limits: limits } } },
      '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
      withLimitsMixin(limits): { spec+: { resources+: { limits+: limits } } },
      '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
      withRequests(requests): { spec+: { resources+: { requests: requests } } },
      '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
      withRequestsMixin(requests): { spec+: { resources+: { requests+: requests } } },
    },
    '#serviceSpec':: d.obj(help='"ServiceSpec that will be added to vmsingle service spec"'),
    serviceSpec: {
      '#metadata':: d.obj(help='"EmbeddedObjectMetadata defines objectMeta for additional service."'),
      metadata: {
        '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be\\nset by external tools to store and retrieve arbitrary metadata. They are not\\nqueryable and should be preserved when modifying objects.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
        withAnnotations(annotations): { spec+: { serviceSpec+: { metadata+: { annotations: annotations } } } },
        '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be\\nset by external tools to store and retrieve arbitrary metadata. They are not\\nqueryable and should be preserved when modifying objects.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
        withAnnotationsMixin(annotations): { spec+: { serviceSpec+: { metadata+: { annotations+: annotations } } } },
        '#withLabels':: d.fn(help='"Labels Map of string keys and values that can be used to organize and categorize\\n(scope and select) objects. May match selectors of replication controllers\\nand services.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels"', args=[d.arg(name='labels', type=d.T.object)]),
        withLabels(labels): { spec+: { serviceSpec+: { metadata+: { labels: labels } } } },
        '#withLabelsMixin':: d.fn(help='"Labels Map of string keys and values that can be used to organize and categorize\\n(scope and select) objects. May match selectors of replication controllers\\nand services.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
        withLabelsMixin(labels): { spec+: { serviceSpec+: { metadata+: { labels+: labels } } } },
        '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although\\nsome resources may allow a client to request the generation of an appropriate name\\nautomatically. Name is primarily intended for creation idempotence and configuration\\ndefinition.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { serviceSpec+: { metadata+: { name: name } } } },
      },
      '#withSpec':: d.fn(help='"ServiceSpec describes the attributes that a user creates on a service.\\nMore info: https://kubernetes.io/docs/concepts/services-networking/service/"', args=[d.arg(name='spec', type=d.T.object)]),
      withSpec(spec): { spec+: { serviceSpec+: { spec: spec } } },
      '#withSpecMixin':: d.fn(help='"ServiceSpec describes the attributes that a user creates on a service.\\nMore info: https://kubernetes.io/docs/concepts/services-networking/service/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='spec', type=d.T.object)]),
      withSpecMixin(spec): { spec+: { serviceSpec+: { spec+: spec } } },
      '#withUseAsDefault':: d.fn(help='"UseAsDefault applies changes from given service definition to the main object Service\\nChanging from headless service to clusterIP or loadbalancer may break cross-component communication"', args=[d.arg(name='useAsDefault', type=d.T.boolean)]),
      withUseAsDefault(useAsDefault): { spec+: { serviceSpec+: { useAsDefault: useAsDefault } } },
    },
    '#storage':: d.obj(help='"Storage is the definition of how storage will be used by the VMSingle\\nby default it`s empty dir\\nthis option is ignored if storageDataPath is set"'),
    storage: {
      '#dataSource':: d.obj(help='"dataSource field can be used to specify either:\\n* An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)\\n* An existing PVC (PersistentVolumeClaim)\\nIf the provisioner or an external controller can support the specified data source,\\nit will create a new volume based on the contents of the specified data source.\\nWhen the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,\\nand dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.\\nIf the namespace is specified, then dataSourceRef will not be copied to dataSource."'),
      dataSource: {
        '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
        withApiGroup(apiGroup): { spec+: { storage+: { dataSource+: { apiGroup: apiGroup } } } },
        '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
        withKind(kind): { spec+: { storage+: { dataSource+: { kind: kind } } } },
        '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { storage+: { dataSource+: { name: name } } } },
      },
      '#dataSourceRef':: d.obj(help="\"dataSourceRef specifies the object from which to populate the volume with data, if a non-empty\\nvolume is desired. This may be any object from a non-empty API group (non\\ncore object) or a PersistentVolumeClaim object.\\nWhen this field is specified, volume binding will only succeed if the type of\\nthe specified object matches some installed volume populator or dynamic\\nprovisioner.\\nThis field will replace the functionality of the dataSource field and as such\\nif both fields are non-empty, they must have the same value. For backwards\\ncompatibility, when namespace isn't specified in dataSourceRef,\\nboth fields (dataSource and dataSourceRef) will be set to the same\\nvalue automatically if one of them is empty and the other is non-empty.\\nWhen namespace is specified in dataSourceRef,\\ndataSource isn't set to the same value and must be empty.\\nThere are three important differences between dataSource and dataSourceRef:\\n* While dataSource only allows two specific types of objects, dataSourceRef\\n  allows any non-core object, as well as PersistentVolumeClaim objects.\\n* While dataSource ignores disallowed values (dropping them), dataSourceRef\\n  preserves all values, and generates an error if a disallowed value is\\n  specified.\\n* While dataSource only allows local objects, dataSourceRef allows objects\\n  in any namespaces.\\n(Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.\\n(Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\""),
      dataSourceRef: {
        '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
        withApiGroup(apiGroup): { spec+: { storage+: { dataSourceRef+: { apiGroup: apiGroup } } } },
        '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
        withKind(kind): { spec+: { storage+: { dataSourceRef+: { kind: kind } } } },
        '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { storage+: { dataSourceRef+: { name: name } } } },
        '#withNamespace':: d.fn(help="\"Namespace is the namespace of resource being referenced\\nNote that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details.\\n(Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\"", args=[d.arg(name='namespace', type=d.T.string)]),
        withNamespace(namespace): { spec+: { storage+: { dataSourceRef+: { namespace: namespace } } } },
      },
      '#resources':: d.obj(help='"resources represents the minimum resources the volume should have.\\nIf RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements\\nthat are lower than previous value but must still be higher than capacity recorded in the\\nstatus field of the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"'),
      resources: {
        '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
        withLimits(limits): { spec+: { storage+: { resources+: { limits: limits } } } },
        '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
        withLimitsMixin(limits): { spec+: { storage+: { resources+: { limits+: limits } } } },
        '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
        withRequests(requests): { spec+: { storage+: { resources+: { requests: requests } } } },
        '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
        withRequestsMixin(requests): { spec+: { storage+: { resources+: { requests+: requests } } } },
      },
      '#selector':: d.obj(help='"selector is a label query over volumes to consider for binding."'),
      selector: {
        '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
        matchExpressions: {
          '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { key: key },
          '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
          withOperator(operator): { operator: operator },
          '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
          withValues(values): { values: if std.isArray(v=values) then values else [values] },
          '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
          withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
        },
        '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
        withMatchExpressions(matchExpressions): { spec+: { storage+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } },
        '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
        withMatchExpressionsMixin(matchExpressions): { spec+: { storage+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } },
        '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabels(matchLabels): { spec+: { storage+: { selector+: { matchLabels: matchLabels } } } },
        '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
        withMatchLabelsMixin(matchLabels): { spec+: { storage+: { selector+: { matchLabels+: matchLabels } } } },
      },
      '#withAccessModes':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"', args=[d.arg(name='accessModes', type=d.T.array)]),
      withAccessModes(accessModes): { spec+: { storage+: { accessModes: if std.isArray(v=accessModes) then accessModes else [accessModes] } } },
      '#withAccessModesMixin':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='accessModes', type=d.T.array)]),
      withAccessModesMixin(accessModes): { spec+: { storage+: { accessModes+: if std.isArray(v=accessModes) then accessModes else [accessModes] } } },
      '#withStorageClassName':: d.fn(help='"storageClassName is the name of the StorageClass required by the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1"', args=[d.arg(name='storageClassName', type=d.T.string)]),
      withStorageClassName(storageClassName): { spec+: { storage+: { storageClassName: storageClassName } } },
      '#withVolumeAttributesClassName':: d.fn(help="\"volumeAttributesClassName may be used to set the VolumeAttributesClass used by this claim.\\nIf specified, the CSI driver will create or update the volume with the attributes defined\\nin the corresponding VolumeAttributesClass. This has a different purpose than storageClassName,\\nit can be changed after the claim is created. An empty string value means that no VolumeAttributesClass\\nwill be applied to the claim but it's not allowed to reset this field to empty string once it is set.\\nIf unspecified and the PersistentVolumeClaim is unbound, the default VolumeAttributesClass\\nwill be set by the persistentvolume controller if it exists.\\nIf the resource referred to by volumeAttributesClass does not exist, this PersistentVolumeClaim will be\\nset to a Pending state, as reflected by the modifyVolumeStatus field, until such as a resource\\nexists.\\nMore info: https://kubernetes.io/docs/concepts/storage/volume-attributes-classes/\\n(Alpha) Using this field requires the VolumeAttributesClass feature gate to be enabled.\"", args=[d.arg(name='volumeAttributesClassName', type=d.T.string)]),
      withVolumeAttributesClassName(volumeAttributesClassName): { spec+: { storage+: { volumeAttributesClassName: volumeAttributesClassName } } },
      '#withVolumeMode':: d.fn(help='"volumeMode defines what type of volume is required by the claim.\\nValue of Filesystem is implied when not included in claim spec."', args=[d.arg(name='volumeMode', type=d.T.string)]),
      withVolumeMode(volumeMode): { spec+: { storage+: { volumeMode: volumeMode } } },
      '#withVolumeName':: d.fn(help='"volumeName is the binding reference to the PersistentVolume backing this claim."', args=[d.arg(name='volumeName', type=d.T.string)]),
      withVolumeName(volumeName): { spec+: { storage+: { volumeName: volumeName } } },
    },
    '#storageMetadata':: d.obj(help='"StorageMeta defines annotations and labels attached to PVC for given vmsingle CR"'),
    storageMetadata: {
      '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be\\nset by external tools to store and retrieve arbitrary metadata. They are not\\nqueryable and should be preserved when modifying objects.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
      withAnnotations(annotations): { spec+: { storageMetadata+: { annotations: annotations } } },
      '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be\\nset by external tools to store and retrieve arbitrary metadata. They are not\\nqueryable and should be preserved when modifying objects.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
      withAnnotationsMixin(annotations): { spec+: { storageMetadata+: { annotations+: annotations } } },
      '#withLabels':: d.fn(help='"Labels Map of string keys and values that can be used to organize and categorize\\n(scope and select) objects. May match selectors of replication controllers\\nand services.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels"', args=[d.arg(name='labels', type=d.T.object)]),
      withLabels(labels): { spec+: { storageMetadata+: { labels: labels } } },
      '#withLabelsMixin':: d.fn(help='"Labels Map of string keys and values that can be used to organize and categorize\\n(scope and select) objects. May match selectors of replication controllers\\nand services.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
      withLabelsMixin(labels): { spec+: { storageMetadata+: { labels+: labels } } },
      '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although\\nsome resources may allow a client to request the generation of an appropriate name\\nautomatically. Name is primarily intended for creation idempotence and configuration\\ndefinition.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names#names"', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { storageMetadata+: { name: name } } },
    },
    '#streamAggrConfig':: d.obj(help='"StreamAggrConfig defines stream aggregation configuration for VMSingle"'),
    streamAggrConfig: {
      '#configmap':: d.obj(help='"ConfigMap with stream aggregation rules"'),
      configmap: {
        '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
        withKey(key): { spec+: { streamAggrConfig+: { configmap+: { key: key } } } },
        '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { streamAggrConfig+: { configmap+: { name: name } } } },
        '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
        withOptional(optional): { spec+: { streamAggrConfig+: { configmap+: { optional: optional } } } },
      },
      '#rules':: d.obj(help='"Stream aggregation rules"'),
      rules: {
        '#input_relabel_configs':: d.obj(help='"InputRelabelConfigs is an optional relabeling rules, which are applied on the input\\nbefore aggregation."'),
        input_relabel_configs: {
          '#withAction':: d.fn(help="\"Action to perform based on regex matching. Default is 'replace'\"", args=[d.arg(name='action', type=d.T.string)]),
          withAction(action): { action: action },
          '#withIf':: d.fn(help="\"If represents metricsQL match expression (or list of expressions): '{__name__=~\\\"foo_.*\\\"}'\"", args=[d.arg(name='If', type=d.T.any)]),
          withIf(If): { 'if': If },
          '#withLabels':: d.fn(help='"Labels is used together with Match for `action: graphite`"', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { labels: labels },
          '#withLabelsMixin':: d.fn(help='"Labels is used together with Match for `action: graphite`"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { labels+: labels },
          '#withMatch':: d.fn(help='"Match is used together with Labels for `action: graphite`"', args=[d.arg(name='match', type=d.T.string)]),
          withMatch(match): { match: match },
          '#withModulus':: d.fn(help='"Modulus to take of the hash of the source label values."', args=[d.arg(name='modulus', type=d.T.integer)]),
          withModulus(modulus): { modulus: modulus },
          '#withRegex':: d.fn(help="\"Regular expression against which the extracted value is matched. Default is '(.*)'\\nvictoriaMetrics supports multiline regex joined with |\\nhttps://docs.victoriametrics.com/vmagent/#relabeling-enhancements\"", args=[d.arg(name='regex', type=d.T.any)]),
          withRegex(regex): { regex: regex },
          '#withReplacement':: d.fn(help="\"Replacement value against which a regex replace is performed if the\\nregular expression matches. Regex capture groups are available. Default is '$1'\"", args=[d.arg(name='replacement', type=d.T.string)]),
          withReplacement(replacement): { replacement: replacement },
          '#withSeparator':: d.fn(help="\"Separator placed between concatenated source label values. default is ';'.\"", args=[d.arg(name='separator', type=d.T.string)]),
          withSeparator(separator): { separator: separator },
          '#withSourceLabels':: d.fn(help='"The source labels select values from existing labels. Their content is concatenated\\nusing the configured separator and matched against the configured regular expression\\nfor the replace, keep, and drop actions."', args=[d.arg(name='sourceLabels', type=d.T.array)]),
          withSourceLabels(sourceLabels): { sourceLabels: if std.isArray(v=sourceLabels) then sourceLabels else [sourceLabels] },
          '#withSourceLabelsMixin':: d.fn(help='"The source labels select values from existing labels. Their content is concatenated\\nusing the configured separator and matched against the configured regular expression\\nfor the replace, keep, and drop actions."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sourceLabels', type=d.T.array)]),
          withSourceLabelsMixin(sourceLabels): { sourceLabels+: if std.isArray(v=sourceLabels) then sourceLabels else [sourceLabels] },
          '#withSource_labels':: d.fn(help='"UnderScoreSourceLabels - additional form of source labels source_labels\\nfor compatibility with original relabel config.\\nif set  both sourceLabels and source_labels, sourceLabels has priority.\\nfor details https://github.com/VictoriaMetrics/operator/issues/131"', args=[d.arg(name='source_labels', type=d.T.array)]),
          withSource_labels(source_labels): { source_labels: if std.isArray(v=source_labels) then source_labels else [source_labels] },
          '#withSource_labelsMixin':: d.fn(help='"UnderScoreSourceLabels - additional form of source labels source_labels\\nfor compatibility with original relabel config.\\nif set  both sourceLabels and source_labels, sourceLabels has priority.\\nfor details https://github.com/VictoriaMetrics/operator/issues/131"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='source_labels', type=d.T.array)]),
          withSource_labelsMixin(source_labels): { source_labels+: if std.isArray(v=source_labels) then source_labels else [source_labels] },
          '#withTargetLabel':: d.fn(help='"Label to which the resulting value is written in a replace action.\\nIt is mandatory for replace actions. Regex capture groups are available."', args=[d.arg(name='targetLabel', type=d.T.string)]),
          withTargetLabel(targetLabel): { targetLabel: targetLabel },
          '#withTarget_label':: d.fn(help='"UnderScoreTargetLabel - additional form of target label - target_label\\nfor compatibility with original relabel config.\\nif set  both targetLabel and target_label, targetLabel has priority.\\nfor details https://github.com/VictoriaMetrics/operator/issues/131"', args=[d.arg(name='target_label', type=d.T.string)]),
          withTarget_label(target_label): { target_label: target_label },
        },
        '#output_relabel_configs':: d.obj(help='"OutputRelabelConfigs is an optional relabeling rules, which are applied\\non the aggregated output before being sent to remote storage."'),
        output_relabel_configs: {
          '#withAction':: d.fn(help="\"Action to perform based on regex matching. Default is 'replace'\"", args=[d.arg(name='action', type=d.T.string)]),
          withAction(action): { action: action },
          '#withIf':: d.fn(help="\"If represents metricsQL match expression (or list of expressions): '{__name__=~\\\"foo_.*\\\"}'\"", args=[d.arg(name='If', type=d.T.any)]),
          withIf(If): { 'if': If },
          '#withLabels':: d.fn(help='"Labels is used together with Match for `action: graphite`"', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { labels: labels },
          '#withLabelsMixin':: d.fn(help='"Labels is used together with Match for `action: graphite`"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { labels+: labels },
          '#withMatch':: d.fn(help='"Match is used together with Labels for `action: graphite`"', args=[d.arg(name='match', type=d.T.string)]),
          withMatch(match): { match: match },
          '#withModulus':: d.fn(help='"Modulus to take of the hash of the source label values."', args=[d.arg(name='modulus', type=d.T.integer)]),
          withModulus(modulus): { modulus: modulus },
          '#withRegex':: d.fn(help="\"Regular expression against which the extracted value is matched. Default is '(.*)'\\nvictoriaMetrics supports multiline regex joined with |\\nhttps://docs.victoriametrics.com/vmagent/#relabeling-enhancements\"", args=[d.arg(name='regex', type=d.T.any)]),
          withRegex(regex): { regex: regex },
          '#withReplacement':: d.fn(help="\"Replacement value against which a regex replace is performed if the\\nregular expression matches. Regex capture groups are available. Default is '$1'\"", args=[d.arg(name='replacement', type=d.T.string)]),
          withReplacement(replacement): { replacement: replacement },
          '#withSeparator':: d.fn(help="\"Separator placed between concatenated source label values. default is ';'.\"", args=[d.arg(name='separator', type=d.T.string)]),
          withSeparator(separator): { separator: separator },
          '#withSourceLabels':: d.fn(help='"The source labels select values from existing labels. Their content is concatenated\\nusing the configured separator and matched against the configured regular expression\\nfor the replace, keep, and drop actions."', args=[d.arg(name='sourceLabels', type=d.T.array)]),
          withSourceLabels(sourceLabels): { sourceLabels: if std.isArray(v=sourceLabels) then sourceLabels else [sourceLabels] },
          '#withSourceLabelsMixin':: d.fn(help='"The source labels select values from existing labels. Their content is concatenated\\nusing the configured separator and matched against the configured regular expression\\nfor the replace, keep, and drop actions."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sourceLabels', type=d.T.array)]),
          withSourceLabelsMixin(sourceLabels): { sourceLabels+: if std.isArray(v=sourceLabels) then sourceLabels else [sourceLabels] },
          '#withSource_labels':: d.fn(help='"UnderScoreSourceLabels - additional form of source labels source_labels\\nfor compatibility with original relabel config.\\nif set  both sourceLabels and source_labels, sourceLabels has priority.\\nfor details https://github.com/VictoriaMetrics/operator/issues/131"', args=[d.arg(name='source_labels', type=d.T.array)]),
          withSource_labels(source_labels): { source_labels: if std.isArray(v=source_labels) then source_labels else [source_labels] },
          '#withSource_labelsMixin':: d.fn(help='"UnderScoreSourceLabels - additional form of source labels source_labels\\nfor compatibility with original relabel config.\\nif set  both sourceLabels and source_labels, sourceLabels has priority.\\nfor details https://github.com/VictoriaMetrics/operator/issues/131"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='source_labels', type=d.T.array)]),
          withSource_labelsMixin(source_labels): { source_labels+: if std.isArray(v=source_labels) then source_labels else [source_labels] },
          '#withTargetLabel':: d.fn(help='"Label to which the resulting value is written in a replace action.\\nIt is mandatory for replace actions. Regex capture groups are available."', args=[d.arg(name='targetLabel', type=d.T.string)]),
          withTargetLabel(targetLabel): { targetLabel: targetLabel },
          '#withTarget_label':: d.fn(help='"UnderScoreTargetLabel - additional form of target label - target_label\\nfor compatibility with original relabel config.\\nif set  both targetLabel and target_label, targetLabel has priority.\\nfor details https://github.com/VictoriaMetrics/operator/issues/131"', args=[d.arg(name='target_label', type=d.T.string)]),
          withTarget_label(target_label): { target_label: target_label },
        },
        '#withBy':: d.fn(help='"By is an optional list of labels for grouping input series.\\n\\nSee also Without.\\n\\nIf neither By nor Without are set, then the Outputs are calculated\\nindividually per each input time series."', args=[d.arg(name='by', type=d.T.array)]),
        withBy(by): { by: if std.isArray(v=by) then by else [by] },
        '#withByMixin':: d.fn(help='"By is an optional list of labels for grouping input series.\\n\\nSee also Without.\\n\\nIf neither By nor Without are set, then the Outputs are calculated\\nindividually per each input time series."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='by', type=d.T.array)]),
        withByMixin(by): { by+: if std.isArray(v=by) then by else [by] },
        '#withDedup_interval':: d.fn(help='"DedupInterval is an optional interval for deduplication."', args=[d.arg(name='dedup_interval', type=d.T.string)]),
        withDedup_interval(dedup_interval): { dedup_interval: dedup_interval },
        '#withDrop_input_labels':: d.fn(help='"DropInputLabels is an optional list with labels, which must be dropped before further processing of input samples.\\n\\nLabels are dropped before de-duplication and aggregation."', args=[d.arg(name='drop_input_labels', type=d.T.array)]),
        withDrop_input_labels(drop_input_labels): { drop_input_labels: if std.isArray(v=drop_input_labels) then drop_input_labels else [drop_input_labels] },
        '#withDrop_input_labelsMixin':: d.fn(help='"DropInputLabels is an optional list with labels, which must be dropped before further processing of input samples.\\n\\nLabels are dropped before de-duplication and aggregation."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop_input_labels', type=d.T.array)]),
        withDrop_input_labelsMixin(drop_input_labels): { drop_input_labels+: if std.isArray(v=drop_input_labels) then drop_input_labels else [drop_input_labels] },
        '#withFlush_on_shutdown':: d.fn(help='"FlushOnShutdown defines whether to flush the aggregation state on process termination\\nor config reload. Is `false` by default.\\nIt is not recommended changing this setting, unless unfinished aggregations states\\nare preferred to missing data points."', args=[d.arg(name='flush_on_shutdown', type=d.T.boolean)]),
        withFlush_on_shutdown(flush_on_shutdown): { flush_on_shutdown: flush_on_shutdown },
        '#withIgnore_first_intervals':: d.fn(help='', args=[d.arg(name='ignore_first_intervals', type=d.T.integer)]),
        withIgnore_first_intervals(ignore_first_intervals): { ignore_first_intervals: ignore_first_intervals },
        '#withIgnore_old_samples':: d.fn(help='"IgnoreOldSamples instructs to ignore samples with old timestamps outside the current aggregation interval."', args=[d.arg(name='ignore_old_samples', type=d.T.boolean)]),
        withIgnore_old_samples(ignore_old_samples): { ignore_old_samples: ignore_old_samples },
        '#withInput_relabel_configs':: d.fn(help='"InputRelabelConfigs is an optional relabeling rules, which are applied on the input\\nbefore aggregation."', args=[d.arg(name='input_relabel_configs', type=d.T.array)]),
        withInput_relabel_configs(input_relabel_configs): { input_relabel_configs: if std.isArray(v=input_relabel_configs) then input_relabel_configs else [input_relabel_configs] },
        '#withInput_relabel_configsMixin':: d.fn(help='"InputRelabelConfigs is an optional relabeling rules, which are applied on the input\\nbefore aggregation."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='input_relabel_configs', type=d.T.array)]),
        withInput_relabel_configsMixin(input_relabel_configs): { input_relabel_configs+: if std.isArray(v=input_relabel_configs) then input_relabel_configs else [input_relabel_configs] },
        '#withInterval':: d.fn(help='"Interval is the interval between aggregations."', args=[d.arg(name='interval', type=d.T.string)]),
        withInterval(interval): { interval: interval },
        '#withKeep_metric_names':: d.fn(help='"KeepMetricNames instructs to leave metric names as is for the output time series without adding any suffix."', args=[d.arg(name='keep_metric_names', type=d.T.boolean)]),
        withKeep_metric_names(keep_metric_names): { keep_metric_names: keep_metric_names },
        '#withMatch':: d.fn(help="\"Match is a label selector (or list of label selectors) for filtering time series for the given selector.\\n\\nIf the match isn't set, then all the input time series are processed.\"", args=[d.arg(name='match', type=d.T.any)]),
        withMatch(match): { match: match },
        '#withNo_align_flush_to_interval':: d.fn(help='"NoAlignFlushToInterval disables aligning of flushes to multiples of Interval.\\nBy default flushes are aligned to Interval."', args=[d.arg(name='no_align_flush_to_interval', type=d.T.boolean)]),
        withNo_align_flush_to_interval(no_align_flush_to_interval): { no_align_flush_to_interval: no_align_flush_to_interval },
        '#withOutput_relabel_configs':: d.fn(help='"OutputRelabelConfigs is an optional relabeling rules, which are applied\\non the aggregated output before being sent to remote storage."', args=[d.arg(name='output_relabel_configs', type=d.T.array)]),
        withOutput_relabel_configs(output_relabel_configs): { output_relabel_configs: if std.isArray(v=output_relabel_configs) then output_relabel_configs else [output_relabel_configs] },
        '#withOutput_relabel_configsMixin':: d.fn(help='"OutputRelabelConfigs is an optional relabeling rules, which are applied\\non the aggregated output before being sent to remote storage."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='output_relabel_configs', type=d.T.array)]),
        withOutput_relabel_configsMixin(output_relabel_configs): { output_relabel_configs+: if std.isArray(v=output_relabel_configs) then output_relabel_configs else [output_relabel_configs] },
        '#withOutputs':: d.fn(help="\"Outputs is a list of output aggregate functions to produce.\\n\\nThe following names are allowed:\\n\\n- total - aggregates input counters\\n- increase - counts the increase over input counters\\n- count_series - counts the input series\\n- count_samples - counts the input samples\\n- sum_samples - sums the input samples\\n- last - the last biggest sample value\\n- min - the minimum sample value\\n- max - the maximum sample value\\n- avg - the average value across all the samples\\n- stddev - standard deviation across all the samples\\n- stdvar - standard variance across all the samples\\n- histogram_bucket - creates VictoriaMetrics histogram for input samples\\n- quantiles(phi1, ..., phiN) - quantiles' estimation for phi in the range [0..1]\\n\\nThe output time series will have the following names:\\n\\n  input_name:aggr_\u003cinterval\u003e_\u003coutput\u003e\"", args=[d.arg(name='outputs', type=d.T.array)]),
        withOutputs(outputs): { outputs: if std.isArray(v=outputs) then outputs else [outputs] },
        '#withOutputsMixin':: d.fn(help="\"Outputs is a list of output aggregate functions to produce.\\n\\nThe following names are allowed:\\n\\n- total - aggregates input counters\\n- increase - counts the increase over input counters\\n- count_series - counts the input series\\n- count_samples - counts the input samples\\n- sum_samples - sums the input samples\\n- last - the last biggest sample value\\n- min - the minimum sample value\\n- max - the maximum sample value\\n- avg - the average value across all the samples\\n- stddev - standard deviation across all the samples\\n- stdvar - standard variance across all the samples\\n- histogram_bucket - creates VictoriaMetrics histogram for input samples\\n- quantiles(phi1, ..., phiN) - quantiles' estimation for phi in the range [0..1]\\n\\nThe output time series will have the following names:\\n\\n  input_name:aggr_\u003cinterval\u003e_\u003coutput\u003e\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='outputs', type=d.T.array)]),
        withOutputsMixin(outputs): { outputs+: if std.isArray(v=outputs) then outputs else [outputs] },
        '#withStaleness_interval':: d.fn(help='"Staleness interval is interval after which the series state will be reset if no samples have been sent during it.\\nThe parameter is only relevant for outputs: total, total_prometheus, increase, increase_prometheus and histogram_bucket."', args=[d.arg(name='staleness_interval', type=d.T.string)]),
        withStaleness_interval(staleness_interval): { staleness_interval: staleness_interval },
        '#withWithout':: d.fn(help='"Without is an optional list of labels, which must be excluded when grouping input series.\\n\\nSee also By.\\n\\nIf neither By nor Without are set, then the Outputs are calculated\\nindividually per each input time series."', args=[d.arg(name='without', type=d.T.array)]),
        withWithout(without): { without: if std.isArray(v=without) then without else [without] },
        '#withWithoutMixin':: d.fn(help='"Without is an optional list of labels, which must be excluded when grouping input series.\\n\\nSee also By.\\n\\nIf neither By nor Without are set, then the Outputs are calculated\\nindividually per each input time series."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='without', type=d.T.array)]),
        withWithoutMixin(without): { without+: if std.isArray(v=without) then without else [without] },
      },
      '#withDedupInterval':: d.fn(help='"Allows setting different de-duplication intervals per each configured remote storage"', args=[d.arg(name='dedupInterval', type=d.T.string)]),
      withDedupInterval(dedupInterval): { spec+: { streamAggrConfig+: { dedupInterval: dedupInterval } } },
      '#withDropInput':: d.fn(help='"Allow drop all the input samples after the aggregation"', args=[d.arg(name='dropInput', type=d.T.boolean)]),
      withDropInput(dropInput): { spec+: { streamAggrConfig+: { dropInput: dropInput } } },
      '#withDropInputLabels':: d.fn(help='"labels to drop from samples for aggregator before stream de-duplication and aggregation"', args=[d.arg(name='dropInputLabels', type=d.T.array)]),
      withDropInputLabels(dropInputLabels): { spec+: { streamAggrConfig+: { dropInputLabels: if std.isArray(v=dropInputLabels) then dropInputLabels else [dropInputLabels] } } },
      '#withDropInputLabelsMixin':: d.fn(help='"labels to drop from samples for aggregator before stream de-duplication and aggregation"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='dropInputLabels', type=d.T.array)]),
      withDropInputLabelsMixin(dropInputLabels): { spec+: { streamAggrConfig+: { dropInputLabels+: if std.isArray(v=dropInputLabels) then dropInputLabels else [dropInputLabels] } } },
      '#withIgnoreFirstIntervals':: d.fn(help='"IgnoreFirstIntervals instructs to ignore first interval"', args=[d.arg(name='ignoreFirstIntervals', type=d.T.integer)]),
      withIgnoreFirstIntervals(ignoreFirstIntervals): { spec+: { streamAggrConfig+: { ignoreFirstIntervals: ignoreFirstIntervals } } },
      '#withIgnoreOldSamples':: d.fn(help='"IgnoreOldSamples instructs to ignore samples with old timestamps outside the current aggregation interval."', args=[d.arg(name='ignoreOldSamples', type=d.T.boolean)]),
      withIgnoreOldSamples(ignoreOldSamples): { spec+: { streamAggrConfig+: { ignoreOldSamples: ignoreOldSamples } } },
      '#withKeepInput':: d.fn(help='"Allows writing both raw and aggregate data"', args=[d.arg(name='keepInput', type=d.T.boolean)]),
      withKeepInput(keepInput): { spec+: { streamAggrConfig+: { keepInput: keepInput } } },
      '#withRules':: d.fn(help='"Stream aggregation rules"', args=[d.arg(name='rules', type=d.T.array)]),
      withRules(rules): { spec+: { streamAggrConfig+: { rules: if std.isArray(v=rules) then rules else [rules] } } },
      '#withRulesMixin':: d.fn(help='"Stream aggregation rules"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='rules', type=d.T.array)]),
      withRulesMixin(rules): { spec+: { streamAggrConfig+: { rules+: if std.isArray(v=rules) then rules else [rules] } } },
    },
    '#tolerations':: d.obj(help="\"Tolerations If specified, the pod's tolerations.\""),
    tolerations: {
      '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
      withEffect(effect): { effect: effect },
      '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
      withKey(key): { key: key },
      '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
      withOperator(operator): { operator: operator },
      '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
      withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
      '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
      withValue(value): { value: value },
    },
    '#vmBackup':: d.obj(help='"VMBackup configuration for backup"'),
    vmBackup: {
      '#credentialsSecret':: d.obj(help='"CredentialsSecret is secret in the same namespace for access to remote storage\\nThe secret is mounted into /etc/vm/creds."'),
      credentialsSecret: {
        '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
        withKey(key): { spec+: { vmBackup+: { credentialsSecret+: { key: key } } } },
        '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { vmBackup+: { credentialsSecret+: { name: name } } } },
        '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
        withOptional(optional): { spec+: { vmBackup+: { credentialsSecret+: { optional: optional } } } },
      },
      '#extraEnvs':: d.obj(help=''),
      extraEnvs: {
        '#valueFrom':: d.obj(help="\"Source for the environment variable's value. Cannot be used if value is not empty.\""),
        valueFrom: {
          '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
          configMapKeyRef: {
            '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { valueFrom+: { configMapKeyRef+: { key: key } } },
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { valueFrom+: { configMapKeyRef+: { name: name } } },
            '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { valueFrom+: { configMapKeyRef+: { optional: optional } } },
          },
          '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
          fieldRef: {
            '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
            withApiVersion(apiVersion): { valueFrom+: { fieldRef+: { apiVersion: apiVersion } } },
            '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
            withFieldPath(fieldPath): { valueFrom+: { fieldRef+: { fieldPath: fieldPath } } },
          },
          '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
          resourceFieldRef: {
            '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
            withContainerName(containerName): { valueFrom+: { resourceFieldRef+: { containerName: containerName } } },
            '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
            withDivisor(divisor): { valueFrom+: { resourceFieldRef+: { divisor: divisor } } },
            '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
            withResource(resource): { valueFrom+: { resourceFieldRef+: { resource: resource } } },
          },
          '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
          secretKeyRef: {
            '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { valueFrom+: { secretKeyRef+: { key: key } } },
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { valueFrom+: { secretKeyRef+: { name: name } } },
            '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { valueFrom+: { secretKeyRef+: { optional: optional } } },
          },
        },
        '#withName':: d.fn(help='"Name of the environment variable. Must be a C_IDENTIFIER."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
        withValue(value): { value: value },
      },
      '#image':: d.obj(help='"Image - docker image settings for VMBackuper"'),
      image: {
        '#withPullPolicy':: d.fn(help='"PullPolicy describes how to pull docker image"', args=[d.arg(name='pullPolicy', type=d.T.string)]),
        withPullPolicy(pullPolicy): { spec+: { vmBackup+: { image+: { pullPolicy: pullPolicy } } } },
        '#withRepository':: d.fn(help="\"Repository contains name of docker image + it's repository if needed\"", args=[d.arg(name='repository', type=d.T.string)]),
        withRepository(repository): { spec+: { vmBackup+: { image+: { repository: repository } } } },
        '#withTag':: d.fn(help='"Tag contains desired docker image version"', args=[d.arg(name='tag', type=d.T.string)]),
        withTag(tag): { spec+: { vmBackup+: { image+: { tag: tag } } } },
      },
      '#resources':: d.obj(help='"Resources container resource request and limits, https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\\nif not defined default resources from operator config will be used"'),
      resources: {
        '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
        claims: {
          '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
        },
        '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
        withClaims(claims): { spec+: { vmBackup+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } },
        '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis is an alpha field and requires enabling the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
        withClaimsMixin(claims): { spec+: { vmBackup+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } },
        '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
        withLimits(limits): { spec+: { vmBackup+: { resources+: { limits: limits } } } },
        '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
        withLimitsMixin(limits): { spec+: { vmBackup+: { resources+: { limits+: limits } } } },
        '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
        withRequests(requests): { spec+: { vmBackup+: { resources+: { requests: requests } } } },
        '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
        withRequestsMixin(requests): { spec+: { vmBackup+: { resources+: { requests+: requests } } } },
      },
      '#restore':: d.obj(help='"Restore Allows to enable restore options for pod\\nRead [more](https://docs.victoriametrics.com/vmbackupmanager#restore-commands)"'),
      restore: {
        '#onStart':: d.obj(help='"OnStart defines configuration for restore on pod start"'),
        onStart: {
          '#withEnabled':: d.fn(help='"Enabled defines if restore on start enabled"', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { vmBackup+: { restore+: { onStart+: { enabled: enabled } } } } },
        },
      },
      '#volumeMounts':: d.obj(help='"VolumeMounts allows configuration of additional VolumeMounts on the output Deployment definition.\\nVolumeMounts specified will be appended to other VolumeMounts in the vmbackupmanager container,\\nthat are generated as a result of StorageSpec objects."'),
      volumeMounts: {
        '#withMountPath':: d.fn(help="\"Path within the container at which the volume should be mounted.  Must\\nnot contain ':'.\"", args=[d.arg(name='mountPath', type=d.T.string)]),
        withMountPath(mountPath): { mountPath: mountPath },
        '#withMountPropagation':: d.fn(help='"mountPropagation determines how mounts are propagated from the host\\nto container and the other way around.\\nWhen not set, MountPropagationNone is used.\\nThis field is beta in 1.10.\\nWhen RecursiveReadOnly is set to IfPossible or to Enabled, MountPropagation must be None or unspecified\\n(which defaults to None)."', args=[d.arg(name='mountPropagation', type=d.T.string)]),
        withMountPropagation(mountPropagation): { mountPropagation: mountPropagation },
        '#withName':: d.fn(help='"This must match the Name of a Volume."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withReadOnly':: d.fn(help='"Mounted read-only if true, read-write otherwise (false or unspecified).\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
        withReadOnly(readOnly): { readOnly: readOnly },
        '#withRecursiveReadOnly':: d.fn(help='"RecursiveReadOnly specifies whether read-only mounts should be handled\\nrecursively.\\n\\nIf ReadOnly is false, this field has no meaning and must be unspecified.\\n\\nIf ReadOnly is true, and this field is set to Disabled, the mount is not made\\nrecursively read-only.  If this field is set to IfPossible, the mount is made\\nrecursively read-only, if it is supported by the container runtime.  If this\\nfield is set to Enabled, the mount is made recursively read-only if it is\\nsupported by the container runtime, otherwise the pod will not be started and\\nan error will be generated to indicate the reason.\\n\\nIf this field is set to IfPossible or Enabled, MountPropagation must be set to\\nNone (or be unspecified, which defaults to None).\\n\\nIf this field is not specified, it is treated as an equivalent of Disabled."', args=[d.arg(name='recursiveReadOnly', type=d.T.string)]),
        withRecursiveReadOnly(recursiveReadOnly): { recursiveReadOnly: recursiveReadOnly },
        '#withSubPath':: d.fn(help="\"Path within the volume from which the container's volume should be mounted.\\nDefaults to \\\"\\\" (volume's root).\"", args=[d.arg(name='subPath', type=d.T.string)]),
        withSubPath(subPath): { subPath: subPath },
        '#withSubPathExpr':: d.fn(help="\"Expanded path within the volume from which the container's volume should be mounted.\\nBehaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment.\\nDefaults to \\\"\\\" (volume's root).\\nSubPathExpr and SubPath are mutually exclusive.\"", args=[d.arg(name='subPathExpr', type=d.T.string)]),
        withSubPathExpr(subPathExpr): { subPathExpr: subPathExpr },
      },
      '#withAcceptEULA':: d.fn(help='"AcceptEULA accepts enterprise feature usage, must be set to true.\\notherwise backupmanager cannot be added to single/cluster version.\\nhttps://victoriametrics.com/legal/esa/"', args=[d.arg(name='acceptEULA', type=d.T.boolean)]),
      withAcceptEULA(acceptEULA): { spec+: { vmBackup+: { acceptEULA: acceptEULA } } },
      '#withConcurrency':: d.fn(help='"Defines number of concurrent workers. Higher concurrency may reduce backup duration (default 10)"', args=[d.arg(name='concurrency', type=d.T.integer)]),
      withConcurrency(concurrency): { spec+: { vmBackup+: { concurrency: concurrency } } },
      '#withCustomS3Endpoint':: d.fn(help='"Custom S3 endpoint for use with S3-compatible storages (e.g. MinIO). S3 is used if not set"', args=[d.arg(name='customS3Endpoint', type=d.T.string)]),
      withCustomS3Endpoint(customS3Endpoint): { spec+: { vmBackup+: { customS3Endpoint: customS3Endpoint } } },
      '#withDestination':: d.fn(help='"Defines destination for backup"', args=[d.arg(name='destination', type=d.T.string)]),
      withDestination(destination): { spec+: { vmBackup+: { destination: destination } } },
      '#withDestinationDisableSuffixAdd':: d.fn(help='"DestinationDisableSuffixAdd - disables suffix adding for cluster version backups\\neach vmstorage backup must have unique backup folder\\nso operator adds POD_NAME as suffix for backup destination folder."', args=[d.arg(name='destinationDisableSuffixAdd', type=d.T.boolean)]),
      withDestinationDisableSuffixAdd(destinationDisableSuffixAdd): { spec+: { vmBackup+: { destinationDisableSuffixAdd: destinationDisableSuffixAdd } } },
      '#withDisableDaily':: d.fn(help='"Defines if daily backups disabled (default false)"', args=[d.arg(name='disableDaily', type=d.T.boolean)]),
      withDisableDaily(disableDaily): { spec+: { vmBackup+: { disableDaily: disableDaily } } },
      '#withDisableHourly':: d.fn(help='"Defines if hourly backups disabled (default false)"', args=[d.arg(name='disableHourly', type=d.T.boolean)]),
      withDisableHourly(disableHourly): { spec+: { vmBackup+: { disableHourly: disableHourly } } },
      '#withDisableMonthly':: d.fn(help='"Defines if monthly backups disabled (default false)"', args=[d.arg(name='disableMonthly', type=d.T.boolean)]),
      withDisableMonthly(disableMonthly): { spec+: { vmBackup+: { disableMonthly: disableMonthly } } },
      '#withDisableWeekly':: d.fn(help='"Defines if weekly backups disabled (default false)"', args=[d.arg(name='disableWeekly', type=d.T.boolean)]),
      withDisableWeekly(disableWeekly): { spec+: { vmBackup+: { disableWeekly: disableWeekly } } },
      '#withExtraArgs':: d.fn(help='"extra args like maxBytesPerSecond default 0"', args=[d.arg(name='extraArgs', type=d.T.object)]),
      withExtraArgs(extraArgs): { spec+: { vmBackup+: { extraArgs: extraArgs } } },
      '#withExtraArgsMixin':: d.fn(help='"extra args like maxBytesPerSecond default 0"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='extraArgs', type=d.T.object)]),
      withExtraArgsMixin(extraArgs): { spec+: { vmBackup+: { extraArgs+: extraArgs } } },
      '#withExtraEnvs':: d.fn(help='', args=[d.arg(name='extraEnvs', type=d.T.array)]),
      withExtraEnvs(extraEnvs): { spec+: { vmBackup+: { extraEnvs: if std.isArray(v=extraEnvs) then extraEnvs else [extraEnvs] } } },
      '#withExtraEnvsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='extraEnvs', type=d.T.array)]),
      withExtraEnvsMixin(extraEnvs): { spec+: { vmBackup+: { extraEnvs+: if std.isArray(v=extraEnvs) then extraEnvs else [extraEnvs] } } },
      '#withLogFormat':: d.fn(help='"LogFormat for VMBackup to be configured with.\\ndefault or json"', args=[d.arg(name='logFormat', type=d.T.string)]),
      withLogFormat(logFormat): { spec+: { vmBackup+: { logFormat: logFormat } } },
      '#withLogLevel':: d.fn(help='"LogLevel for VMBackup to be configured with."', args=[d.arg(name='logLevel', type=d.T.string)]),
      withLogLevel(logLevel): { spec+: { vmBackup+: { logLevel: logLevel } } },
      '#withPort':: d.fn(help='"Port for health check connections"', args=[d.arg(name='port', type=d.T.string)]),
      withPort(port): { spec+: { vmBackup+: { port: port } } },
      '#withSnapshotCreateURL':: d.fn(help='"SnapshotCreateURL overwrites url for snapshot create"', args=[d.arg(name='snapshotCreateURL', type=d.T.string)]),
      withSnapshotCreateURL(snapshotCreateURL): { spec+: { vmBackup+: { snapshotCreateURL: snapshotCreateURL } } },
      '#withSnapshotDeleteURL':: d.fn(help='"SnapShotDeleteURL overwrites url for snapshot delete"', args=[d.arg(name='snapshotDeleteURL', type=d.T.string)]),
      withSnapshotDeleteURL(snapshotDeleteURL): { spec+: { vmBackup+: { snapshotDeleteURL: snapshotDeleteURL } } },
      '#withVolumeMounts':: d.fn(help='"VolumeMounts allows configuration of additional VolumeMounts on the output Deployment definition.\\nVolumeMounts specified will be appended to other VolumeMounts in the vmbackupmanager container,\\nthat are generated as a result of StorageSpec objects."', args=[d.arg(name='volumeMounts', type=d.T.array)]),
      withVolumeMounts(volumeMounts): { spec+: { vmBackup+: { volumeMounts: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] } } },
      '#withVolumeMountsMixin':: d.fn(help='"VolumeMounts allows configuration of additional VolumeMounts on the output Deployment definition.\\nVolumeMounts specified will be appended to other VolumeMounts in the vmbackupmanager container,\\nthat are generated as a result of StorageSpec objects."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumeMounts', type=d.T.array)]),
      withVolumeMountsMixin(volumeMounts): { spec+: { vmBackup+: { volumeMounts+: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] } } },
    },
    '#volumeMounts':: d.obj(help='"VolumeMounts allows configuration of additional VolumeMounts on the output Deployment/StatefulSet definition.\\nVolumeMounts specified will be appended to other VolumeMounts in the Application container"'),
    volumeMounts: {
      '#withMountPath':: d.fn(help="\"Path within the container at which the volume should be mounted.  Must\\nnot contain ':'.\"", args=[d.arg(name='mountPath', type=d.T.string)]),
      withMountPath(mountPath): { mountPath: mountPath },
      '#withMountPropagation':: d.fn(help='"mountPropagation determines how mounts are propagated from the host\\nto container and the other way around.\\nWhen not set, MountPropagationNone is used.\\nThis field is beta in 1.10.\\nWhen RecursiveReadOnly is set to IfPossible or to Enabled, MountPropagation must be None or unspecified\\n(which defaults to None)."', args=[d.arg(name='mountPropagation', type=d.T.string)]),
      withMountPropagation(mountPropagation): { mountPropagation: mountPropagation },
      '#withName':: d.fn(help='"This must match the Name of a Volume."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { name: name },
      '#withReadOnly':: d.fn(help='"Mounted read-only if true, read-write otherwise (false or unspecified).\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
      withReadOnly(readOnly): { readOnly: readOnly },
      '#withRecursiveReadOnly':: d.fn(help='"RecursiveReadOnly specifies whether read-only mounts should be handled\\nrecursively.\\n\\nIf ReadOnly is false, this field has no meaning and must be unspecified.\\n\\nIf ReadOnly is true, and this field is set to Disabled, the mount is not made\\nrecursively read-only.  If this field is set to IfPossible, the mount is made\\nrecursively read-only, if it is supported by the container runtime.  If this\\nfield is set to Enabled, the mount is made recursively read-only if it is\\nsupported by the container runtime, otherwise the pod will not be started and\\nan error will be generated to indicate the reason.\\n\\nIf this field is set to IfPossible or Enabled, MountPropagation must be set to\\nNone (or be unspecified, which defaults to None).\\n\\nIf this field is not specified, it is treated as an equivalent of Disabled."', args=[d.arg(name='recursiveReadOnly', type=d.T.string)]),
      withRecursiveReadOnly(recursiveReadOnly): { recursiveReadOnly: recursiveReadOnly },
      '#withSubPath':: d.fn(help="\"Path within the volume from which the container's volume should be mounted.\\nDefaults to \\\"\\\" (volume's root).\"", args=[d.arg(name='subPath', type=d.T.string)]),
      withSubPath(subPath): { subPath: subPath },
      '#withSubPathExpr':: d.fn(help="\"Expanded path within the volume from which the container's volume should be mounted.\\nBehaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment.\\nDefaults to \\\"\\\" (volume's root).\\nSubPathExpr and SubPath are mutually exclusive.\"", args=[d.arg(name='subPathExpr', type=d.T.string)]),
      withSubPathExpr(subPathExpr): { subPathExpr: subPathExpr },
    },
    '#withAffinity':: d.fn(help="\"Affinity If specified, the pod's scheduling constraints.\"", args=[d.arg(name='affinity', type=d.T.object)]),
    withAffinity(affinity): { spec+: { affinity: affinity } },
    '#withAffinityMixin':: d.fn(help="\"Affinity If specified, the pod's scheduling constraints.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='affinity', type=d.T.object)]),
    withAffinityMixin(affinity): { spec+: { affinity+: affinity } },
    '#withConfigMaps':: d.fn(help='"ConfigMaps is a list of ConfigMaps in the same namespace as the Application\\nobject, which shall be mounted into the Application container\\nat /etc/vm/configs/CONFIGMAP_NAME folder"', args=[d.arg(name='configMaps', type=d.T.array)]),
    withConfigMaps(configMaps): { spec+: { configMaps: if std.isArray(v=configMaps) then configMaps else [configMaps] } },
    '#withConfigMapsMixin':: d.fn(help='"ConfigMaps is a list of ConfigMaps in the same namespace as the Application\\nobject, which shall be mounted into the Application container\\nat /etc/vm/configs/CONFIGMAP_NAME folder"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='configMaps', type=d.T.array)]),
    withConfigMapsMixin(configMaps): { spec+: { configMaps+: if std.isArray(v=configMaps) then configMaps else [configMaps] } },
    '#withContainers':: d.fn(help='"Containers property allows to inject additions sidecars or to patch existing containers.\\nIt can be useful for proxies, backup, etc."', args=[d.arg(name='containers', type=d.T.array)]),
    withContainers(containers): { spec+: { containers: if std.isArray(v=containers) then containers else [containers] } },
    '#withContainersMixin':: d.fn(help='"Containers property allows to inject additions sidecars or to patch existing containers.\\nIt can be useful for proxies, backup, etc."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='containers', type=d.T.array)]),
    withContainersMixin(containers): { spec+: { containers+: if std.isArray(v=containers) then containers else [containers] } },
    '#withDisableSelfServiceScrape':: d.fn(help='"DisableSelfServiceScrape controls creation of VMServiceScrape by operator\\nfor the application.\\nHas priority over `VM_DISABLESELFSERVICESCRAPECREATION` operator env variable"', args=[d.arg(name='disableSelfServiceScrape', type=d.T.boolean)]),
    withDisableSelfServiceScrape(disableSelfServiceScrape): { spec+: { disableSelfServiceScrape: disableSelfServiceScrape } },
    '#withDnsPolicy':: d.fn(help='"DNSPolicy sets DNS policy for the pod"', args=[d.arg(name='dnsPolicy', type=d.T.string)]),
    withDnsPolicy(dnsPolicy): { spec+: { dnsPolicy: dnsPolicy } },
    '#withExtraArgs':: d.fn(help='"ExtraArgs that will be passed to the application container\\nfor example remoteWrite.tmpDataPath: /tmp"', args=[d.arg(name='extraArgs', type=d.T.object)]),
    withExtraArgs(extraArgs): { spec+: { extraArgs: extraArgs } },
    '#withExtraArgsMixin':: d.fn(help='"ExtraArgs that will be passed to the application container\\nfor example remoteWrite.tmpDataPath: /tmp"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='extraArgs', type=d.T.object)]),
    withExtraArgsMixin(extraArgs): { spec+: { extraArgs+: extraArgs } },
    '#withExtraEnvs':: d.fn(help='"ExtraEnvs that will be passed to the application container"', args=[d.arg(name='extraEnvs', type=d.T.array)]),
    withExtraEnvs(extraEnvs): { spec+: { extraEnvs: if std.isArray(v=extraEnvs) then extraEnvs else [extraEnvs] } },
    '#withExtraEnvsMixin':: d.fn(help='"ExtraEnvs that will be passed to the application container"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='extraEnvs', type=d.T.array)]),
    withExtraEnvsMixin(extraEnvs): { spec+: { extraEnvs+: if std.isArray(v=extraEnvs) then extraEnvs else [extraEnvs] } },
    '#withHostAliases':: d.fn(help='"HostAliases provides mapping for ip and hostname,\\nthat would be propagated to pod,\\ncannot be used with HostNetwork."', args=[d.arg(name='hostAliases', type=d.T.array)]),
    withHostAliases(hostAliases): { spec+: { hostAliases: if std.isArray(v=hostAliases) then hostAliases else [hostAliases] } },
    '#withHostAliasesMixin':: d.fn(help='"HostAliases provides mapping for ip and hostname,\\nthat would be propagated to pod,\\ncannot be used with HostNetwork."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='hostAliases', type=d.T.array)]),
    withHostAliasesMixin(hostAliases): { spec+: { hostAliases+: if std.isArray(v=hostAliases) then hostAliases else [hostAliases] } },
    '#withHostNetwork':: d.fn(help='"HostNetwork controls whether the pod may use the node network namespace"', args=[d.arg(name='hostNetwork', type=d.T.boolean)]),
    withHostNetwork(hostNetwork): { spec+: { hostNetwork: hostNetwork } },
    '#withHost_aliases':: d.fn(help='"HostAliasesUnderScore provides mapping for ip and hostname,\\nthat would be propagated to pod,\\ncannot be used with HostNetwork.\\nHas Priority over hostAliases field"', args=[d.arg(name='host_aliases', type=d.T.array)]),
    withHost_aliases(host_aliases): { spec+: { host_aliases: if std.isArray(v=host_aliases) then host_aliases else [host_aliases] } },
    '#withHost_aliasesMixin':: d.fn(help='"HostAliasesUnderScore provides mapping for ip and hostname,\\nthat would be propagated to pod,\\ncannot be used with HostNetwork.\\nHas Priority over hostAliases field"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='host_aliases', type=d.T.array)]),
    withHost_aliasesMixin(host_aliases): { spec+: { host_aliases+: if std.isArray(v=host_aliases) then host_aliases else [host_aliases] } },
    '#withImagePullSecrets':: d.fn(help='"ImagePullSecrets An optional list of references to secrets in the same namespace\\nto use for pulling images from registries\\nsee https://kubernetes.io/docs/concepts/containers/images/#referring-to-an-imagepullsecrets-on-a-pod"', args=[d.arg(name='imagePullSecrets', type=d.T.array)]),
    withImagePullSecrets(imagePullSecrets): { spec+: { imagePullSecrets: if std.isArray(v=imagePullSecrets) then imagePullSecrets else [imagePullSecrets] } },
    '#withImagePullSecretsMixin':: d.fn(help='"ImagePullSecrets An optional list of references to secrets in the same namespace\\nto use for pulling images from registries\\nsee https://kubernetes.io/docs/concepts/containers/images/#referring-to-an-imagepullsecrets-on-a-pod"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='imagePullSecrets', type=d.T.array)]),
    withImagePullSecretsMixin(imagePullSecrets): { spec+: { imagePullSecrets+: if std.isArray(v=imagePullSecrets) then imagePullSecrets else [imagePullSecrets] } },
    '#withInitContainers':: d.fn(help='"InitContainers allows adding initContainers to the pod definition.\\nAny errors during the execution of an initContainer will lead to a restart of the Pod.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/"', args=[d.arg(name='initContainers', type=d.T.array)]),
    withInitContainers(initContainers): { spec+: { initContainers: if std.isArray(v=initContainers) then initContainers else [initContainers] } },
    '#withInitContainersMixin':: d.fn(help='"InitContainers allows adding initContainers to the pod definition.\\nAny errors during the execution of an initContainer will lead to a restart of the Pod.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='initContainers', type=d.T.array)]),
    withInitContainersMixin(initContainers): { spec+: { initContainers+: if std.isArray(v=initContainers) then initContainers else [initContainers] } },
    '#withLivenessProbe':: d.fn(help='"LivenessProbe that will be added CRD pod"', args=[d.arg(name='livenessProbe', type=d.T.object)]),
    withLivenessProbe(livenessProbe): { spec+: { livenessProbe: livenessProbe } },
    '#withLivenessProbeMixin':: d.fn(help='"LivenessProbe that will be added CRD pod"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='livenessProbe', type=d.T.object)]),
    withLivenessProbeMixin(livenessProbe): { spec+: { livenessProbe+: livenessProbe } },
    '#withLogFormat':: d.fn(help='"LogFormat for VMSingle to be configured with."', args=[d.arg(name='logFormat', type=d.T.string)]),
    withLogFormat(logFormat): { spec+: { logFormat: logFormat } },
    '#withLogLevel':: d.fn(help='"LogLevel for victoria metrics single to be configured with."', args=[d.arg(name='logLevel', type=d.T.string)]),
    withLogLevel(logLevel): { spec+: { logLevel: logLevel } },
    '#withMinReadySeconds':: d.fn(help='"MinReadySeconds defines a minim number os seconds to wait before starting update next pod\\nif previous in healthy state\\nHas no effect for VLogs and VMSingle"', args=[d.arg(name='minReadySeconds', type=d.T.integer)]),
    withMinReadySeconds(minReadySeconds): { spec+: { minReadySeconds: minReadySeconds } },
    '#withNodeSelector':: d.fn(help='"NodeSelector Define which Nodes the Pods are scheduled on."', args=[d.arg(name='nodeSelector', type=d.T.object)]),
    withNodeSelector(nodeSelector): { spec+: { nodeSelector: nodeSelector } },
    '#withNodeSelectorMixin':: d.fn(help='"NodeSelector Define which Nodes the Pods are scheduled on."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelector', type=d.T.object)]),
    withNodeSelectorMixin(nodeSelector): { spec+: { nodeSelector+: nodeSelector } },
    '#withPaused':: d.fn(help='"Paused If set to true all actions on the underlying managed objects are not\\ngoing to be performed, except for delete actions."', args=[d.arg(name='paused', type=d.T.boolean)]),
    withPaused(paused): { spec+: { paused: paused } },
    '#withPort':: d.fn(help='"Port listen address"', args=[d.arg(name='port', type=d.T.string)]),
    withPort(port): { spec+: { port: port } },
    '#withPriorityClassName':: d.fn(help='"PriorityClassName class assigned to the Pods"', args=[d.arg(name='priorityClassName', type=d.T.string)]),
    withPriorityClassName(priorityClassName): { spec+: { priorityClassName: priorityClassName } },
    '#withReadinessGates':: d.fn(help='"ReadinessGates defines pod readiness gates"', args=[d.arg(name='readinessGates', type=d.T.array)]),
    withReadinessGates(readinessGates): { spec+: { readinessGates: if std.isArray(v=readinessGates) then readinessGates else [readinessGates] } },
    '#withReadinessGatesMixin':: d.fn(help='"ReadinessGates defines pod readiness gates"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='readinessGates', type=d.T.array)]),
    withReadinessGatesMixin(readinessGates): { spec+: { readinessGates+: if std.isArray(v=readinessGates) then readinessGates else [readinessGates] } },
    '#withReadinessProbe':: d.fn(help='"ReadinessProbe that will be added CRD pod"', args=[d.arg(name='readinessProbe', type=d.T.object)]),
    withReadinessProbe(readinessProbe): { spec+: { readinessProbe: readinessProbe } },
    '#withReadinessProbeMixin':: d.fn(help='"ReadinessProbe that will be added CRD pod"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='readinessProbe', type=d.T.object)]),
    withReadinessProbeMixin(readinessProbe): { spec+: { readinessProbe+: readinessProbe } },
    '#withRemovePvcAfterDelete':: d.fn(help='"RemovePvcAfterDelete - if true, controller adds ownership to pvc\\nand after VMSingle object deletion - pvc will be garbage collected\\nby controller manager"', args=[d.arg(name='removePvcAfterDelete', type=d.T.boolean)]),
    withRemovePvcAfterDelete(removePvcAfterDelete): { spec+: { removePvcAfterDelete: removePvcAfterDelete } },
    '#withReplicaCount':: d.fn(help='"ReplicaCount is the expected size of the Application."', args=[d.arg(name='replicaCount', type=d.T.integer)]),
    withReplicaCount(replicaCount): { spec+: { replicaCount: replicaCount } },
    '#withRetentionPeriod':: d.fn(help='"RetentionPeriod for the stored metrics\\nNote VictoriaMetrics has data/ and indexdb/ folders\\nmetrics from data/ removed eventually as soon as partition leaves retention period\\nreverse index data at indexdb rotates once at the half of configured [retention period](https://docs.victoriametrics.com/Single-server-VictoriaMetrics/#retention)"', args=[d.arg(name='retentionPeriod', type=d.T.string)]),
    withRetentionPeriod(retentionPeriod): { spec+: { retentionPeriod: retentionPeriod } },
    '#withRevisionHistoryLimitCount':: d.fn(help='"The number of old ReplicaSets to retain to allow rollback in deployment or\\nmaximum number of revisions that will be maintained in the Deployment revision history.\\nHas no effect at StatefulSets\\nDefaults to 10."', args=[d.arg(name='revisionHistoryLimitCount', type=d.T.integer)]),
    withRevisionHistoryLimitCount(revisionHistoryLimitCount): { spec+: { revisionHistoryLimitCount: revisionHistoryLimitCount } },
    '#withRuntimeClassName':: d.fn(help='"RuntimeClassName - defines runtime class for kubernetes pod.\\nhttps://kubernetes.io/docs/concepts/containers/runtime-class/"', args=[d.arg(name='runtimeClassName', type=d.T.string)]),
    withRuntimeClassName(runtimeClassName): { spec+: { runtimeClassName: runtimeClassName } },
    '#withSchedulerName':: d.fn(help='"SchedulerName - defines kubernetes scheduler name"', args=[d.arg(name='schedulerName', type=d.T.string)]),
    withSchedulerName(schedulerName): { spec+: { schedulerName: schedulerName } },
    '#withSecrets':: d.fn(help='"Secrets is a list of Secrets in the same namespace as the Application\\nobject, which shall be mounted into the Application container\\nat /etc/vm/secrets/SECRET_NAME folder"', args=[d.arg(name='secrets', type=d.T.array)]),
    withSecrets(secrets): { spec+: { secrets: if std.isArray(v=secrets) then secrets else [secrets] } },
    '#withSecretsMixin':: d.fn(help='"Secrets is a list of Secrets in the same namespace as the Application\\nobject, which shall be mounted into the Application container\\nat /etc/vm/secrets/SECRET_NAME folder"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='secrets', type=d.T.array)]),
    withSecretsMixin(secrets): { spec+: { secrets+: if std.isArray(v=secrets) then secrets else [secrets] } },
    '#withSecurityContext':: d.fn(help='"SecurityContext holds pod-level security attributes and common container settings.\\nThis defaults to the default PodSecurityContext."', args=[d.arg(name='securityContext', type=d.T.object)]),
    withSecurityContext(securityContext): { spec+: { securityContext: securityContext } },
    '#withSecurityContextMixin':: d.fn(help='"SecurityContext holds pod-level security attributes and common container settings.\\nThis defaults to the default PodSecurityContext."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='securityContext', type=d.T.object)]),
    withSecurityContextMixin(securityContext): { spec+: { securityContext+: securityContext } },
    '#withServiceAccountName':: d.fn(help='"ServiceAccountName is the name of the ServiceAccount to use to run the pods"', args=[d.arg(name='serviceAccountName', type=d.T.string)]),
    withServiceAccountName(serviceAccountName): { spec+: { serviceAccountName: serviceAccountName } },
    '#withServiceScrapeSpec':: d.fn(help='"ServiceScrapeSpec that will be added to vmsingle VMServiceScrape spec"', args=[d.arg(name='serviceScrapeSpec', type=d.T.object)]),
    withServiceScrapeSpec(serviceScrapeSpec): { spec+: { serviceScrapeSpec: serviceScrapeSpec } },
    '#withServiceScrapeSpecMixin':: d.fn(help='"ServiceScrapeSpec that will be added to vmsingle VMServiceScrape spec"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='serviceScrapeSpec', type=d.T.object)]),
    withServiceScrapeSpecMixin(serviceScrapeSpec): { spec+: { serviceScrapeSpec+: serviceScrapeSpec } },
    '#withStartupProbe':: d.fn(help='"StartupProbe that will be added to CRD pod"', args=[d.arg(name='startupProbe', type=d.T.object)]),
    withStartupProbe(startupProbe): { spec+: { startupProbe: startupProbe } },
    '#withStartupProbeMixin':: d.fn(help='"StartupProbe that will be added to CRD pod"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='startupProbe', type=d.T.object)]),
    withStartupProbeMixin(startupProbe): { spec+: { startupProbe+: startupProbe } },
    '#withStorageDataPath':: d.fn(help='"StorageDataPath disables spec.storage option and overrides arg for victoria-metrics binary --storageDataPath,\\nits users responsibility to mount proper device into given path.\\nIt requires to provide spec.volumes and spec.volumeMounts with at least 1 value"', args=[d.arg(name='storageDataPath', type=d.T.string)]),
    withStorageDataPath(storageDataPath): { spec+: { storageDataPath: storageDataPath } },
    '#withTerminationGracePeriodSeconds':: d.fn(help='"TerminationGracePeriodSeconds period for container graceful termination"', args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
    withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { spec+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
    '#withTolerations':: d.fn(help="\"Tolerations If specified, the pod's tolerations.\"", args=[d.arg(name='tolerations', type=d.T.array)]),
    withTolerations(tolerations): { spec+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } },
    '#withTolerationsMixin':: d.fn(help="\"Tolerations If specified, the pod's tolerations.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='tolerations', type=d.T.array)]),
    withTolerationsMixin(tolerations): { spec+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } },
    '#withTopologySpreadConstraints':: d.fn(help='"TopologySpreadConstraints embedded kubernetes pod configuration option,\\ncontrols how pods are spread across your cluster among failure-domains\\nsuch as regions, zones, nodes, and other user-defined topology domains\\nhttps://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/"', args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
    withTopologySpreadConstraints(topologySpreadConstraints): { spec+: { topologySpreadConstraints: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] } },
    '#withTopologySpreadConstraintsMixin':: d.fn(help='"TopologySpreadConstraints embedded kubernetes pod configuration option,\\ncontrols how pods are spread across your cluster among failure-domains\\nsuch as regions, zones, nodes, and other user-defined topology domains\\nhttps://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
    withTopologySpreadConstraintsMixin(topologySpreadConstraints): { spec+: { topologySpreadConstraints+: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] } },
    '#withUseDefaultResources':: d.fn(help='"UseDefaultResources controls resource settings\\nBy default, operator sets built-in resource requirements"', args=[d.arg(name='useDefaultResources', type=d.T.boolean)]),
    withUseDefaultResources(useDefaultResources): { spec+: { useDefaultResources: useDefaultResources } },
    '#withUseStrictSecurity':: d.fn(help='"UseStrictSecurity enables strict security mode for component\\nit restricts disk writes access\\nuses non-root user out of the box\\ndrops not needed security permissions"', args=[d.arg(name='useStrictSecurity', type=d.T.boolean)]),
    withUseStrictSecurity(useStrictSecurity): { spec+: { useStrictSecurity: useStrictSecurity } },
    '#withVolumeMounts':: d.fn(help='"VolumeMounts allows configuration of additional VolumeMounts on the output Deployment/StatefulSet definition.\\nVolumeMounts specified will be appended to other VolumeMounts in the Application container"', args=[d.arg(name='volumeMounts', type=d.T.array)]),
    withVolumeMounts(volumeMounts): { spec+: { volumeMounts: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] } },
    '#withVolumeMountsMixin':: d.fn(help='"VolumeMounts allows configuration of additional VolumeMounts on the output Deployment/StatefulSet definition.\\nVolumeMounts specified will be appended to other VolumeMounts in the Application container"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumeMounts', type=d.T.array)]),
    withVolumeMountsMixin(volumeMounts): { spec+: { volumeMounts+: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] } },
    '#withVolumes':: d.fn(help='"Volumes allows configuration of additional volumes on the output Deployment/StatefulSet definition.\\nVolumes specified will be appended to other volumes that are generated.\\n/ +optional"', args=[d.arg(name='volumes', type=d.T.array)]),
    withVolumes(volumes): { spec+: { volumes: if std.isArray(v=volumes) then volumes else [volumes] } },
    '#withVolumesMixin':: d.fn(help='"Volumes allows configuration of additional volumes on the output Deployment/StatefulSet definition.\\nVolumes specified will be appended to other volumes that are generated.\\n/ +optional"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumes', type=d.T.array)]),
    withVolumesMixin(volumes): { spec+: { volumes+: if std.isArray(v=volumes) then volumes else [volumes] } },
  },
  '#mixin': 'ignore',
  mixin: self,
}
